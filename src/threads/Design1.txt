
CIS 520 - Programming Project #1

                   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Carson Holt <cdh1522@k-state.edu>
Ahmed Alhkraissi <aalkhraissi@k-state.edu>
...

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for
>> the TA, or extra credit, please give them here.
-- Dan approved a one-week extension for us, as Carson's partner
-- dropped the class, leaving him teamless until 2/13.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation,
>> course text, lecture notes, and course staff.
   https://github.com/yuwumichcn223/pintos
   https://github.com/yuan901202/pintos_1
   https://github.com/codyjack/Pintos/blob/master/pintos/src/devices/timer.c

                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
   struct thread *t = thread_current(); defines the current thread.
   int64_t wakeup_time = start + ticks; schedules the time to wake up


---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to your timer_sleep(),
>> including the effects of the timer interrupt handler.
   When timer_sleep() is called, the current thread is given a variable, t.
   Interrupts are confirmed to be on, then are disabled. The wakeup time
   for the thread is scheduled, and t is pushed to the back of the thread list.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?
   - Interrupts are disabled before letting the semaphore down.


---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?
   Mutual exclusion disallows two threads to use one process.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?
   Interrupts are turned off, and mutual exclusion is used.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> other designs that you considered?
   I chose the design with semaphores because a) semaphores can be used
   more widely than locks and b) semaphores are safer than calling
   thread_block() and thread_unblock() directly


             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
static struct list block_list;
#define DEPTH_LIMIT 8
enum intr_level old_level;


>> B2: Explain the data structure used to track priority donation.
Priority donation is tracked by 1) keeping track of all locks that a thread
holds, 2) holding a reference to the thread owning a lock, and 3) keeping
a list of all threads waiting for a lock.

 ----------    held locks     ----------                   ----------
|          |   --------->    |          |                 |          |
|  Thread  |   lock holder   |   Lock   |   ---------->   |Semaphore |
|          |   <---------    |          |                 |          |
|          |                  ----------                  |          |
|          |               waiting threads                |          |
|          |        <---------------------------          |          |
 ----------                                                ----------

1) is achieved using a new list in thread struct and the corresponding element
member in thread lock. 2) as well as 3) were already part of the existing lock
implementation.

At all times, a thread's priority is the maximum of its static priority (set
by thread_set_priority() and its donated priority. The donated priority is
determined recursively by querying all held locks for maximum priority held
by a thread on its waiting list, which again returns the maximum of the threads'
static and donated priorities.

These data structures are updated whenever lock_acquire(), lock_try_acquire(),
and lock_release() are called.

real pri: 3              real pri: 3              real pri: 3
 --------                 --------                 --------
|Thread A|  waits for X  |Thread B|  waits for Y  |Thread C|
|pri: 1  | <------------ |pri: 2  | <------------ |pri: 3  |
|locks: X|               |locks: Y|               |        |
 --------                 --------                 --------

In the case of nested priority donation (see diagram), in order to determine the
real priority of thread A, we have to determine the real priority of B, which in
turn requires us to determine the real priority of C. To do this we could call
thread_get_priority_of() for each thread, waiting for A and then recursively
call it for every thread waiting for any of those and so on. This takes time and
if the threads are in a deadlock it may never return.

This is prevented by using thread_get_priority_recursive() which takes an
integer argument and increases it for every level of waiting threads. If
thread_get_priority_recursive() is called with an argument > PRI_MAX_RECURSION
it returns without calling itself again.


---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?
The priority of all threads on the waiting list are determined as described
above (B2). The first thread with maximum priority is chosen and unblocked.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?
Lock acquire causes sema_down() to be called on the internal semaphore. No
changes have been made to sema_down() in this project - if the process can
enter, the semaphore value is decremented. Otherwise, it is put on the waiters
list and blocked. The scheduler then chooses the first thread with the highest
priority to run next.

Once it has entered successfully, the lock holder is saved, and the lock is
entered into the thread's list of held locks.

Combined with the process described in B2, this is sufficient to handle
priority donation. There is no special handling for nested donations. Recursive
priority calculation in thread_get_priority_recursive() handles this case
with ease.


>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

The lock holder is set to NULL and the lock is removed from the held locks 
list. sema_up() is then called, which goes through all threads on the waiting
list and unblocks the first one with maximum priority. Since the unblocked
thread has a higher priority than the currently running thread, thread_yield()
is called and the unblocked thread is scheduled.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

In general, if thread_set_priority() does any bookkeeping (i.e. modifying lists,
changing the thread struct) and is interrupted by for example a thread waking up
from a timer, the state of the thread system may be corrupted.

This cannot happen in our implementation as we only change thread->priority, and then
calculate the actual priorities (after donation) on the fly. Thus if the thread
is interrupted while changing its priority it either has the new, or the old
priority and the next thread to run is determined by using thread_get_priority_of().

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

Using recursive priority calculation is simple. There is very little
book-keeping involved - only held locks and waiting threads must be saved. The
waiting list was already provided by the semaphore implementation. Special
cases like nested donation handle themselves.

This design has issues when a wait cycle is concerned, since it will enter
an infinite recursion when trying to calculate thread priority.

This is prevented by limiting the depth of the recursion as described in B2.

Another design we considered was calculating actual thread priority whenever
something caused it to change (lock_acquire(), lock_release(), thread creation,
etc). An advantage to this design was that much less superfluous calculation was
required. However, it seemed to be much harder to keep track of changes correctly.


              ADVANCED SCHEDULER [EXTRA CREDIT]
              =================================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0
 4
 8
12
16
20
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

